{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import zipfile\n",
    "import sklearn\n",
    "import shutil\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend('agg')\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision.utils as vutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import zipfile\n",
    "import tempfile\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"\n",
    "    reads image from path and shape it into (c,h,w)\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path, 0)  # Assuming the image is grayscale\n",
    "    img_array = np.array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add channel dimension\n",
    "    return img_array\n",
    "\n",
    "\n",
    "def format_name(zip_file_name):\n",
    "    \"\"\"\n",
    "    reads zip file name and format it into lower case\n",
    "    \"\"\"\n",
    "    formatted_name = zip_file_name.replace(\".zip\", \"\").replace(\"_\", \" \").lower()\n",
    "    return formatted_name\n",
    "\n",
    "\n",
    "class BldgDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path=\"./data/experiments/casestudy.zip\",\n",
    "        mode=\"train\",\n",
    "        transform=None,\n",
    "        seq_len=5,\n",
    "        num_seq=6,\n",
    "        num_frame=30,\n",
    "    ):\n",
    "        super(BldgDataset, self).__init__()\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.seq_len = seq_len\n",
    "        self.num_seq = num_seq\n",
    "        self.building_names = []\n",
    "        self.num_frame = num_frame  # 30 frames each path\n",
    "\n",
    "        # Load dataset\n",
    "        self.data = []\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.load_dataset()\n",
    "\n",
    "    def load_dataset(self):\n",
    "        sum_pixels = np.float64(0)\n",
    "        sum_pixels_squared = np.float64(0)\n",
    "        pixel_count = np.float64(0)\n",
    "        # Extract the main zip file if needed\n",
    "        with zipfile.ZipFile(self.data_path, \"r\") as main_zip:\n",
    "            with tempfile.TemporaryDirectory() as temp_dir:\n",
    "                main_zip.extractall(temp_dir)\n",
    "\n",
    "                # Iterate over each building sequence label zip file inside the main directory\n",
    "                for bldg_zip_name in main_zip.namelist():\n",
    "                    bldg_route_label = format_name(bldg_zip_name)\n",
    "                    route = bldg_route_label[\n",
    "                        -1\n",
    "                    ]  # The last character is the route label a,b,c,d\n",
    "                    bldg = bldg_route_label[:-2]\n",
    "                    if bldg not in self.building_names:\n",
    "                        self.building_names.append(bldg)\n",
    "\n",
    "                    # Extract the building sequence label zip file\n",
    "                    bldg_zip_path = os.path.join(temp_dir, bldg_zip_name)\n",
    "                    with zipfile.ZipFile(bldg_zip_path, \"r\") as bldg_zip:\n",
    "                        bldg_temp_dir = os.path.join(temp_dir, bldg_route_label)\n",
    "                        bldg_zip.extractall(bldg_temp_dir)\n",
    "\n",
    "                        # Iterate over path folders\n",
    "                        for path_folder in tqdm(\n",
    "                            sorted(os.listdir(bldg_temp_dir)),\n",
    "                            desc=f\"Loading {bldg}\",\n",
    "                            unit=\"path\",\n",
    "                        ):\n",
    "                            if path_folder.startswith(\"path\"):\n",
    "                                path_images = []\n",
    "                                path_folder_full = os.path.join(\n",
    "                                    bldg_temp_dir, path_folder\n",
    "                                )\n",
    "\n",
    "                                for frame in range(\n",
    "                                    self.num_frame\n",
    "                                ):  # Assuming 30 frames per path\n",
    "                                    img_filename = f\"panoramic_{frame:02d}.png\"\n",
    "                                    img_path = os.path.join(\n",
    "                                        path_folder_full, img_filename\n",
    "                                    )\n",
    "                                    if os.path.exists(img_path):\n",
    "                                        img_array = read_image(img_path).astype(\n",
    "                                            np.float64\n",
    "                                        )\n",
    "                                        path_images.append(img_array)\n",
    "                                        # Update the sums for mean and std calculation\n",
    "                                        sum_pixels += img_array.sum()\n",
    "                                        sum_pixels_squared += (img_array**2).sum()\n",
    "                                        pixel_count += img_array.size\n",
    "\n",
    "                                # Only consider complete sequences with 30 frames\n",
    "                                if len(path_images) != self.num_frame:\n",
    "                                    print(\n",
    "                                        f\"Error: {bldg}, Route {route}, Path {path_folder} does not have 30 images.\"\n",
    "                                    )\n",
    "                                    return\n",
    "                                else:\n",
    "                                    self.data.append(\n",
    "                                        {\n",
    "                                            \"images\": np.concatenate(\n",
    "                                                path_images, axis=0\n",
    "                                            ),\n",
    "                                            \"path\": int(\n",
    "                                                re.search(r\"\\d+\", path_folder).group()\n",
    "                                            ),\n",
    "                                            \"route\": route,\n",
    "                                            \"bldg\": bldg,\n",
    "                                        }\n",
    "                                    )\n",
    "        self.mean = sum_pixels / pixel_count\n",
    "        variance = (sum_pixels_squared / pixel_count) - (self.mean**2)\n",
    "        if variance < 0:\n",
    "            if np.isclose(variance, 0):\n",
    "                self.std = 0\n",
    "            else:\n",
    "                raise ValueError(f\"Calculated negative variance: {variance}\")\n",
    "        else:\n",
    "            self.std = np.sqrt(variance)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        imgs = item[\"images\"]\n",
    "        t_imgs = imgs.reshape(-1, 1, 30, 60)  # num_frame, C, H, W\n",
    "        # Apply transform if provided\n",
    "        if self.transform:\n",
    "            t_imgs = self.transform(t_imgs)\n",
    "        t_imgs = np.stack(t_imgs, axis=0)\n",
    "        t_imgs = torch.from_numpy(t_imgs).float()\n",
    "        # normalize\n",
    "        t_imgs = (t_imgs - self.mean) / self.std\n",
    "        (C, H, W) = t_imgs[0].size()\n",
    "        t_imgs = t_imgs.view(self.num_seq, self.seq_len, C, H, W).transpose(\n",
    "            1, 2\n",
    "        )  # num_seq,C,seq_len,H,W\n",
    "\n",
    "        # Return data as a dictionary\n",
    "        return {\n",
    "            \"t_imgs\": t_imgs,\n",
    "            \"imgs\": imgs,\n",
    "            \"path\": item[\"path\"],\n",
    "            \"route\": item[\"route\"],\n",
    "            \"bldg\": item[\"bldg\"],\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def find_indices(self, bldg_name, route, path_number):\n",
    "        \"\"\"\n",
    "        Finds the indices of the data items that match the given building, route, and path number.\n",
    "\n",
    "        :param bldg_name: The name of the building (formatted as 'caracalla baths', for example).\n",
    "        :param route: The route label (a single character like 'a', 'b', etc.).\n",
    "        :param path_number: The path number (an integer).\n",
    "        :return: A list of indices that match the criteria.\n",
    "        \"\"\"\n",
    "        indices = []\n",
    "        for idx, item in enumerate(self.data):\n",
    "            if (\n",
    "                item[\"bldg\"].lower() == bldg_name.lower()\n",
    "                and item[\"route\"].lower() == route.lower()\n",
    "                and item[\"path\"] == path_number\n",
    "            ):\n",
    "                indices.append(idx)\n",
    "        return indices\n",
    "\n",
    "    def plot_one_sequence(self, idx):\n",
    "        \"\"\"take idx of the data , plot the sequence\"\"\"\n",
    "        path = self[idx][\"path\"]\n",
    "        imgs = self[idx][\"imgs\"]\n",
    "        bldg = self[idx][\"bldg\"]\n",
    "        route = self[idx][\"route\"]\n",
    "        for img in imgs:\n",
    "            fig = plt.figure()\n",
    "            ax = fig.add_subplot(1, 1, 1)\n",
    "            ax.set_title(f\"{bldg} route {route} path {path}\")\n",
    "            plt.imshow(img.reshape(30, 60), cmap=\"gray\", vmin=0, vmax=255)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 262.28path/s]\n",
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 252.62path/s]\n",
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 267.88path/s]\n",
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 258.91path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 249.92path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 269.39path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 252.80path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 244.84path/s]\n",
      "Loading pantheon: 100%|██████████| 100/100 [00:00<00:00, 262.34path/s]\n",
      "Loading pantheon: 100%|██████████| 100/100 [00:00<00:00, 243.83path/s]\n",
      "Loading pantheon: 100%|██████████| 100/100 [00:00<00:00, 269.62path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 251.69path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 256.96path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 272.90path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 252.75path/s]\n",
      "Loading trenton bath house: 100%|██████████| 100/100 [00:00<00:00, 259.82path/s]\n",
      "Loading trenton bath house: 100%|██████████| 100/100 [00:00<00:00, 252.81path/s]\n",
      "Loading trenton bath house: 100%|██████████| 100/100 [00:00<00:00, 245.79path/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caracalla baths', 'india institute of management', 'pantheon', 'trajans market', 'trenton bath house']\n",
      "99.77257469135803\n",
      "92.27697774383148\n"
     ]
    }
   ],
   "source": [
    "# Example of how to use the dataset\n",
    "dataset = BldgDataset()\n",
    "print(dataset.building_names)\n",
    "print(dataset.mean)\n",
    "print(dataset.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30, 60)\n",
      "torch.Size([6, 1, 5, 30, 60])\n",
      "caracalla baths\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][\"imgs\"].shape)\n",
    "print(dataset[0][\"t_imgs\"].shape)\n",
    "print(dataset[0][\"bldg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot_one_sequence(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F\n",
    "import numbers\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, imgmap):\n",
    "        return [torch.from_numpy(img.copy()).float() for img in imgmap]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrightnessJitter(object):  # 0.5 to 5 is a good range\n",
    "    def __init__(self, brightness=0, consistent=True, p=0.5):\n",
    "        self.brightness = self._check_input(brightness, \"brightness\")\n",
    "        self.consistent = consistent\n",
    "        self.threshold = p\n",
    "\n",
    "    def _check_input(\n",
    "        self, value, name, center=1, bound=(0, float(\"inf\")), clip_first_on_zero=True\n",
    "    ):\n",
    "        if isinstance(value, numbers.Number):\n",
    "            if value < 0:\n",
    "                raise ValueError(\n",
    "                    \"If {} is a single number, it must be non negative.\".format(name)\n",
    "                )\n",
    "            value = [center - value, center + value]\n",
    "            if clip_first_on_zero:\n",
    "                value[0] = max(value[0], 0)\n",
    "        elif isinstance(value, (tuple, list)) and len(value) == 2:\n",
    "            if not bound[0] <= value[0] <= value[1] <= bound[1]:\n",
    "                raise ValueError(\"{} values should be between {}\".format(name, bound))\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"{} should be a single number or a list/tuple with lenght 2.\".format(\n",
    "                    name\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if value[0] == value[1] == center:\n",
    "            value = None\n",
    "        return value\n",
    "\n",
    "    @staticmethod\n",
    "    def get_params(brightness):\n",
    "        transforms = []\n",
    "\n",
    "        if brightness is not None:\n",
    "            brightness_factor = random.uniform(brightness[0], brightness[1])\n",
    "            transforms.append(lambda img: img * brightness_factor)\n",
    "\n",
    "        transform = torchvision.transforms.Compose(transforms)\n",
    "\n",
    "        return transform\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        if random.random() < self.threshold:  # do BrightnessJitter\n",
    "            if self.consistent:\n",
    "                transform = self.get_params(self.brightness)\n",
    "                return [transform(i) for i in imgmap]\n",
    "            else:\n",
    "                result = []\n",
    "                for img in imgmap:\n",
    "                    transform = self.get_params(self.brightness)\n",
    "                    result.append(transform(img))\n",
    "                return result\n",
    "        else:  # don't do BrightnessJitter, do nothing\n",
    "            return imgmap\n",
    "\n",
    "    def __repr__(self):\n",
    "        format_string = self.__class__.__name__ + \"(\"\n",
    "        format_string += \"brightness={0}\".format(self.brightness)\n",
    "        format_string += \")\"\n",
    "        return format_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to test\n",
    "class RandomHorizontalShift:\n",
    "    def __init__(self, max_shift=30, p=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            max_shift (int): the maximum number of pixels for the horizontal shift.\n",
    "            p (float): probability of applying the shift. Default is 0.5.\n",
    "        \"\"\"\n",
    "        self.max_shift = max_shift\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        return [self.horizontal_shift(img) for img in imgmap]\n",
    "\n",
    "    def horizontal_shift(self, img):\n",
    "        \"\"\"\n",
    "        Shift the image horizontally by a random number of pixels and wrap around.\n",
    "        Args:\n",
    "            img (ndarray): the input image as a numpy array.\n",
    "        Returns:\n",
    "            img (ndarray): the transformed image as a numpy array.\n",
    "        \"\"\"\n",
    "        # Check if we should apply the shift based on the probability p\n",
    "        if random.random() < self.p:\n",
    "            shift = random.randint(0, self.max_shift)\n",
    "            shifted_np_img = np.roll(img, shift, axis=2)  # roll along width dimension\n",
    "            return shifted_np_img\n",
    "        return img  # return original image if not shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip:  # choose consistent to be false\n",
    "    def __init__(self, consistent=True, p=0.5):\n",
    "        self.consistent = consistent\n",
    "        self.threshold = p\n",
    "\n",
    "    def __call__(self, imgmap):\n",
    "        if self.consistent:\n",
    "            if random.random() > self.threshold:\n",
    "                return [np.flip(i, axis=[0, 2]) for i in imgmap]\n",
    "            else:\n",
    "                return imgmap\n",
    "        else:\n",
    "            result = []\n",
    "            for i in imgmap:\n",
    "                if random.random() > self.threshold:\n",
    "                    result.append(np.flip(i, axis=[0, 2]))\n",
    "                else:\n",
    "                    result.append(i)\n",
    "            assert len(result) == len(imgmap)\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Of Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset[0][\"imgs\"][:10]\n",
    "brightness_jitter_transform = BrightnessJitter(\n",
    "    brightness=[0.5, 5], consistent=False, p=1\n",
    ")\n",
    "brightness_jittered_dataset = brightness_jitter_transform(test_dataset)\n",
    "print(len(brightness_jittered_dataset[0]))\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    img = brightness_jittered_dataset[i]\n",
    "    ax.set_title(f\"img {i}\")\n",
    "    ax.imshow(img.reshape(30, 60), cmap=\"gray\", vmin=0, vmax=255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.reshape(-1, 1, 30, 60)\n",
    "horizontal_shift_transform = RandomHorizontalShift(max_shift=60)\n",
    "shifted_dataset = horizontal_shift_transform(test_dataset)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    img = shifted_dataset[i]\n",
    "    ax.set_title(f\"Img {i}\")\n",
    "    ax.imshow(img.reshape(30, 60), cmap=\"gray\", vmin=0, vmax=255)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizontal_flip_transform = RandomHorizontalFlip(consistent=os.truncate, p=0.5)\n",
    "flipped_dataset = horizontal_flip_transform(test_dataset)\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    origin = test_dataset[i]\n",
    "    flipped = flipped_dataset[i]\n",
    "\n",
    "    axes[0].set_title(\"Original\")\n",
    "    axes[0].imshow(origin.reshape(30, 60), cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "    axes[1].set_title(\"Flipped\")\n",
    "    axes[1].imshow(flipped.reshape(30, 60), cmap=\"gray\", vmin=0, vmax=255)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 254.94path/s]\n",
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 254.73path/s]\n",
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 255.97path/s]\n",
      "Loading caracalla baths: 100%|██████████| 100/100 [00:00<00:00, 256.23path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 255.18path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 261.80path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 251.77path/s]\n",
      "Loading india institute of management: 100%|██████████| 100/100 [00:00<00:00, 256.07path/s]\n",
      "Loading pantheon: 100%|██████████| 100/100 [00:00<00:00, 254.27path/s]\n",
      "Loading pantheon: 100%|██████████| 100/100 [00:00<00:00, 239.45path/s]\n",
      "Loading pantheon: 100%|██████████| 100/100 [00:00<00:00, 260.91path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 250.24path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 263.33path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 258.36path/s]\n",
      "Loading trajans market: 100%|██████████| 100/100 [00:00<00:00, 257.49path/s]\n",
      "Loading trenton bath house: 100%|██████████| 100/100 [00:00<00:00, 259.49path/s]\n",
      "Loading trenton bath house: 100%|██████████| 100/100 [00:00<00:00, 249.51path/s]\n",
      "Loading trenton bath house: 100%|██████████| 100/100 [00:00<00:00, 258.38path/s]\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        RandomHorizontalFlip(consistent=True, p=0.5),\n",
    "        BrightnessJitter(brightness=[0.5, 5], consistent=True, p=0.5),\n",
    "        RandomHorizontalShift(max_shift=60, p=0.5),\n",
    "    ]\n",
    ")\n",
    "test_transform = BldgDataset(transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1890)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transform[5][\"t_imgs\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
