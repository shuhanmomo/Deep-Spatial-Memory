{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet2d3d_full(\n",
      "  (conv1): Conv3d(1, 64, kernel_size=(1, 5, 5), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock2d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock2d(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from backbone.resnet_2d3d import resnet18_2d3d_simplified\n",
    "\n",
    "resModel = resnet18_2d3d_simplified()\n",
    "print(resModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([96, 128, 2, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "test_tensor = torch.randn(96, 1, 5, 30, 60)\n",
    "output = resModel(test_tensor)\n",
    "# Print the output size\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading demo: 100%|██████████| 300/300 [00:01<00:00, 239.00path/s]\n",
      "Loading demo: 100%|██████████| 300/300 [00:01<00:00, 261.99path/s]\n"
     ]
    }
   ],
   "source": [
    "from helpers.dataset import BldgDataset\n",
    "\n",
    "dataset = BldgDataset(\"./DemoExperiment/1117/demo_test.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "\n",
    "def preprocess_image_data(base_path, zip_name):\n",
    "    # Unzip the file\n",
    "    zip_path = os.path.join(base_path, zip_name)\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(base_path)\n",
    "\n",
    "    # Iterate through each 'pathXX' folder and rename PNGs using a temporary name\n",
    "    for i in range(300):\n",
    "        folder_name = f\"path{str(i).zfill(2)}\"\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "\n",
    "        # First, rename to temporary names\n",
    "        for j in range(30):\n",
    "            old_name = f\"panoramic_{str(j).zfill(2)}.png\"\n",
    "            temp_name = f\"temp_{str(j).zfill(2)}.png\"\n",
    "            old_path = os.path.join(folder_path, old_name)\n",
    "            temp_path = os.path.join(folder_path, temp_name)\n",
    "\n",
    "            if os.path.exists(old_path):\n",
    "                os.rename(old_path, temp_path)\n",
    "\n",
    "        # Then, rename temporary files to the final names\n",
    "        for j in range(30):\n",
    "            temp_name = f\"temp_{str(j).zfill(2)}.png\"\n",
    "            new_name = f\"panoramic_{str(29-j).zfill(2)}.png\"\n",
    "            temp_path = os.path.join(folder_path, temp_name)\n",
    "            new_path = os.path.join(folder_path, new_name)\n",
    "\n",
    "            if os.path.exists(temp_path):\n",
    "                os.rename(temp_path, new_path)\n",
    "\n",
    "        print(f\"Finished processing folder {folder_name}\")\n",
    "\n",
    "    # Rezip the folders with the new name\n",
    "    new_zip_name_parts = zip_name[:-4].split(\"_\")  # Split the original zip name\n",
    "    new_zip_name_parts[1], new_zip_name_parts[2] = (\n",
    "        new_zip_name_parts[2],\n",
    "        new_zip_name_parts[1],\n",
    "    )  # Swap 'start' and 'end'\n",
    "    new_zip_name = \"_\".join(new_zip_name_parts) + \".zip\"\n",
    "\n",
    "    with zipfile.ZipFile(os.path.join(base_path, new_zip_name), \"w\") as zipf:\n",
    "        for i in range(300):\n",
    "            folder_name = f\"path{str(i).zfill(2)}\"\n",
    "            folder_path = os.path.join(base_path, folder_name)\n",
    "            for root, dirs, files in os.walk(folder_path):\n",
    "                for file in files:\n",
    "                    zipf.write(\n",
    "                        os.path.join(root, file),\n",
    "                        os.path.relpath(os.path.join(root, file), base_path),\n",
    "                    )\n",
    "\n",
    "    # Optional: Delete the path folders after re-zipping\n",
    "    for i in range(300):\n",
    "        shutil.rmtree(os.path.join(base_path, f\"path{str(i).zfill(2)}\"))\n",
    "\n",
    "\n",
    "# Usage\n",
    "preprocess_image_data(\"./DemoExperiment/process\", \"demo_corridor_room_a.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "args = {\n",
    "    \"net\": \"resnet18\",\n",
    "    \"model\": \"memdpc\",\n",
    "    \"dataset\": \"BldgDataset\",\n",
    "    \"seq_len\": 5,  # to 5\n",
    "    \"num_seq\": 6,  # to 6\n",
    "    \"pred_step\": 3,  # to 2\n",
    "    \"ds\": 3,\n",
    "    \"mem_size\": 512,  # 1024\n",
    "    \"batch_size\": 8,  # 4\n",
    "    \"lr\": 1e-3,\n",
    "    \"wd\": 1e-5,\n",
    "    \"resume\": \"\",\n",
    "    \"pretrain\": \"\",\n",
    "    \"epochs\": 500,\n",
    "    \"start_epoch\": 0,\n",
    "    \"gpu\": \"0,1\",\n",
    "    \"print_freq\": 5,\n",
    "    \"reset_lr\": False,\n",
    "    \"prefix\": \"tmp\",\n",
    "    \"img_dim\": [30, 60],\n",
    "    \"seed\": 0,\n",
    "    \"workers\": 16,\n",
    "    \"p\": 0.8,  # probability to apply data augmentation\n",
    "    \"data_path\": \"casestudy.zip\",\n",
    "}\n",
    "with open(\"config.json\", \"w\") as f:\n",
    "    json.dump(args, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
